{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gribName=\"20210610_0616_9e528005\"\n",
    "cyc_name=str.upper(\"Carlos\")\n",
    "grbs = pygrib.open('.\\\\Data\\\\'+gribName+'.grib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grb=grbs[1:]\n",
    "grb.append(grbs[len(grb)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_grbs=grbs.select(shortName=\"u\",typeOfLevel='isobaricInhPa',level=[500,700,800,925,1000])\n",
    "#selected_grbs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "numChannels=12\n",
    "gridShape=(221,381)\n",
    "framesPerDay=24\n",
    "isoLvls=[500,700,850,925,1000]\n",
    "numIsoLvls=len(isoLvls)\n",
    "numFrames=len(grb)\n",
    "numDays=numFrames//(numChannels*framesPerDay*numIsoLvls)\n",
    "#INDEX=Frame*5*12+IsoLvl*12+Channel (tot=12*5*24*numDays)\n",
    "assert numFrames%(numChannels*framesPerDay*numIsoLvls)==0 #Having integer number of days\n",
    "assert grb[1].values.shape==gridShape #Check grid shape matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstFrame=grb[0]['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grb[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grb[0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 5, 12, 221, 381)\n"
     ]
    }
   ],
   "source": [
    "arr=np.zeros(shape=(numDays*framesPerDay,numIsoLvls,numChannels,*gridShape),dtype=\"float32\")\n",
    "print(arr.shape)\n",
    "\n",
    "def parseIndices(i):\n",
    "    timeLoc=i//(numChannels*numIsoLvls)\n",
    "    isoLoc=(i-timeLoc*(numChannels*numIsoLvls))//numChannels\n",
    "    channelLoc=i-timeLoc*(numChannels*numIsoLvls)-isoLoc*numChannels\n",
    "    return timeLoc,isoLoc,channelLoc\n",
    "\n",
    "#INDEX=Frame*60+IsoLvl*12+Channel (tot=12*5*24*numDays)\n",
    "for i,v in enumerate(grb):\n",
    "    arr[*parseIndices(i)] = v.values.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseIndices(247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255.15921021, 255.20413208, 255.25784302, ..., 261.86038208,\n",
       "        261.82131958, 261.75881958],\n",
       "       [255.78030396, 255.83792114, 255.90237427, ..., 261.72073364,\n",
       "        261.69924927, 261.65628052],\n",
       "       [256.40432739, 256.46585083, 256.53225708, ..., 261.65139771,\n",
       "        261.64456177, 261.63870239],\n",
       "       ...,\n",
       "       [269.43557739, 269.40921021, 269.38870239, ..., 270.67288208,\n",
       "        270.59866333, 270.53421021],\n",
       "       [269.62112427, 269.57913208, 269.54397583, ..., 270.75881958,\n",
       "        270.71487427, 270.66116333],\n",
       "       [269.80862427, 269.76565552, 269.72659302, ..., 270.74514771,\n",
       "        270.74612427, 270.72366333]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grb[247].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grb\n",
    "del grbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming `arr` is your ndarray with the shape (numDays*framesPerDay, numIsoLvls, numChannels, *gridShape)\n",
    "def normalize_channels(data):\n",
    "    # data.shape should be (numDays*framesPerDay, numIsoLvls, numChannels, height, width)\n",
    "\n",
    "    # Initialize a new array to hold the normalized data\n",
    "    normalized_data = np.zeros_like(data, dtype=np.float32)\n",
    "    \n",
    "    # Iterate over each channel to normalize\n",
    "    for channel in range(data.shape[2]):  # Assuming the third index is for channels\n",
    "        # Extract the channel data\n",
    "        channel_data = data[:, :, channel, :, :]\n",
    "        \n",
    "        # Compute the min and max\n",
    "        min_val = np.min(channel_data)\n",
    "        max_val = np.max(channel_data)\n",
    "        \n",
    "        # Avoid division by zero in case all values in the channel are the same\n",
    "        if max_val > min_val:\n",
    "            # Normalize the channel\n",
    "            normalized_data[:, :, channel, :, :] = (channel_data - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            # If max equals min, set the normalized data to zero or handle appropriately\n",
    "            normalized_data[:, :, channel, :, :] = 0  # Or set it to a neutral value like 0.5 if more appropriate\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "# Apply the normalization to your data\n",
    "normalized_arr = normalize_channels(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming normalized_arr is your ndarray\n",
    "# Example shape of normalized_arr is (numDays*framesPerDay, numIsoLvls, numChannels, height, width)\n",
    "# We need to transform it to (numDays*framesPerDay, height, width, numChannels*numIsoLvls)\n",
    "\n",
    "# First, let's transpose the axes to bring all spatial dimensions next to each other\n",
    "# Transpose (0, 3, 4, 1, 2) means:\n",
    "# 0 -> 0 (keep numDays*framesPerDay at the first axis)\n",
    "# 1 -> 3 (move the first spatial dimension to second place)\n",
    "# 2 -> 4 (move the second spatial dimension to third place)\n",
    "# 3 -> 1 (move numIsoLvls to the last but one)\n",
    "# 4 -> 2 (move numChannels to the last position)\n",
    "transposed_arr = np.transpose(normalized_arr, (0, 3, 4, 1, 2))\n",
    "\n",
    "# Now, we need to merge the last two dimensions (numIsoLvls and numChannels)\n",
    "# Calculate the new dimension\n",
    "new_last_dim = transposed_arr.shape[3] * transposed_arr.shape[4]\n",
    "\n",
    "# Reshape to merge the last two dimensions\n",
    "inTensor = transposed_arr.reshape(transposed_arr.shape[0], transposed_arr.shape[1], transposed_arr.shape[2], new_last_dim)\n",
    "\n",
    "# reshaped_arr now has the shape (numDays*framesPerDay, height, width, numChannels*numIsoLvls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">381</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">381</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">219</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">379</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,312</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>,   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24320</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24326</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432,700</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m221\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m381\u001b[0m, \u001b[38;5;34m60\u001b[0m)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m381\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m60\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m219\u001b[0m, \u001b[38;5;34m379\u001b[0m,  │     \u001b[38;5;34m17,312\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m126\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m124\u001b[0m,   │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m41\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m39\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m19\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24320\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24326\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │  \u001b[38;5;34m2,432,700\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m404\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,542,768</span> (9.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,542,768\u001b[0m (9.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,542,768</span> (9.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,542,768\u001b[0m (9.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming each \"frame\" is an independent input not wrapped in TimeDistributed\n",
    "input_layer = Input(shape=(13, *gridShape, 60))  # Adjust based on your exact gridShape and channel info\n",
    "\n",
    "# CNN layers applied independently to each frame (you might need a loop or custom layer here)\n",
    "# Simplified version: Applying CNN to the first frame for illustration (adjust this part!)\n",
    "cnn_out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input_layer[:,0,:,:,:])\n",
    "cnn_out = MaxPooling2D(pool_size=(3, 3))(cnn_out)\n",
    "cnn_out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(cnn_out)\n",
    "cnn_out = MaxPooling2D(pool_size=(3, 3))(cnn_out)\n",
    "cnn_out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(cnn_out)\n",
    "cnn_out = MaxPooling2D(pool_size=(2, 2))(cnn_out)\n",
    "cnn_out = Flatten()(cnn_out)\n",
    "\n",
    "# Scalar inputs for the best track data at present (shape=(6,))\n",
    "best_track_input = Input(shape=(6,))\n",
    "\n",
    "# Concatenate the scalar values with the output of the CNN\n",
    "combined_inputs = Concatenate(axis=-1)([cnn_out, best_track_input])\n",
    "\n",
    "# Dense layers for final prediction\n",
    "dense_out = Dense(units=100, activation='relu')(combined_inputs)\n",
    "output = Dense(units=4)(dense_out)  # Predicting values for the cyclone's next location\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=[input_layer, best_track_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_Track=pd.read_csv(\"BestTrack_Trimmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_Track['ISO_TIME']=pd.to_datetime(best_Track['ISO_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime=pd.to_datetime(gribName[:8],format='%Y%m%d')\n",
    "endtime=starttime+pd.Timedelta(days=numDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fBesttrack=best_Track[(best_Track['ISO_TIME']>=starttime)&(best_Track['ISO_TIME']<=endtime)&(best_Track['LAT']>=0.0)&(best_Track['LAT']<=90.0)&(best_Track['LON']>=-170.0)&(best_Track['LON']<=-80.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fBesttrack=fBesttrack[fBesttrack['NAME']==cyc_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = fBesttrack[['USA_WIND', 'USA_PRES', 'LAT', 'LON','ISO_TIME']]\n",
    "selected_columns=selected_columns[selected_columns['ISO_TIME'].dt.hour%3==0]\n",
    "def normalize(value, min_val, max_val):\n",
    "    return (value - min_val) / (max_val - min_val)\n",
    "\n",
    "# Define the ranges\n",
    "lat_min, lat_max = 0, 40\n",
    "lon_min, lon_max = -170, -80\n",
    "wind_min, wind_max = 20, 200\n",
    "pressure_min, pressure_max = 860, 1020\n",
    "\n",
    "# Normalize the data\n",
    "selected_columns['LAT'] = normalize(selected_columns['LAT'], lat_min, lat_max)\n",
    "selected_columns['LON'] = normalize(selected_columns['LON'], lon_min, lon_max)\n",
    "selected_columns['USA_WIND'] = normalize(selected_columns['USA_WIND'].astype(float), wind_min, wind_max)\n",
    "selected_columns['USA_PRES'] = normalize(selected_columns['USA_PRES'].astype(float), pressure_min, pressure_max)\n",
    "selected_columns['ISO_DATE'] = selected_columns['ISO_TIME'].dt.dayofyear/365\n",
    "selected_columns['ISO_TIME'] = selected_columns['ISO_TIME'].dt.hour/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "starttimeb=fBesttrack['ISO_TIME'].iloc[0]\n",
    "endtimeb=fBesttrack['ISO_TIME'].iloc[-1]\n",
    "assert (endtimeb-starttimeb)/datetime.timedelta(seconds=3*3600) == len(selected_columns)-1 #same frame count\n",
    "\n",
    "besttrack_ndarr=selected_columns.to_numpy().astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('ibtracs.EP.list.v04r00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trim=df[['SID','NAME','SEASON','NUMBER','NATURE','ISO_TIME','LAT','LON','WMO_WIND','WMO_PRES','USA_RECORD','USA_STATUS','USA_WIND','USA_PRES','USA_GUST']][1:]\n",
    "# df_trim['SEASON']=pd.to_numeric(df_trim['SEASON'])\n",
    "# df_trim=df_trim[df_trim['SEASON']>=2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trim.to_csv('BestTrack_Trimmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "d"
    ]
   },
   "outputs": [],
   "source": [
    "#import cdsapi\n",
    "#c = cdsapi.Client()\n",
    "#c.retrieve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1618255376815796"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inTensor.size*inTensor.itemsize)/(1024*1024*1024)#in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrameinA=int((starttimeb-starttime)/datetime.timedelta(hours=1))\n",
    "endFrameinA=int((endtimeb-starttime)/datetime.timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def Bdx_to_Adx(bdx, startFrameinA):\n",
    "    \"\"\" Converts an index in best track data to its corresponding index in inTensor. \"\"\"\n",
    "    return bdx * 3 + startFrameinA\n",
    "\n",
    "def data_generator(inTensor, besttrack_ndarr, startFrameinA, endFrameinA, scope=12, forecast_horizon=6):\n",
    "    \"\"\"\n",
    "    Generator function to yield individual training data samples and labels.\n",
    "    \"\"\"\n",
    "    # Calculate the number of samples available for generation\n",
    "    num_samples = len(besttrack_ndarr) - forecast_horizon // 3\n",
    "    indices = np.arange(0, num_samples)\n",
    "    np.random.shuffle(indices)  # Shuffle indices for random sampling\n",
    "    \n",
    "    while True:  # Loop indefinitely for continuous generation\n",
    "        for idx in indices:\n",
    "            # Calculate starting frame index for inTensor based on best track data index\n",
    "            start_idx = Bdx_to_Adx(idx, startFrameinA) - scope\n",
    "            end_idx = Bdx_to_Adx(idx, startFrameinA) + 1\n",
    "            \n",
    "            # Generate input frames from inTensor\n",
    "            cnn_input = np.stack(inTensor[start_idx:end_idx])\n",
    "            \n",
    "            # Get corresponding best track input\n",
    "            track_input = besttrack_ndarr[idx]\n",
    "            \n",
    "            # Prepare target output based on forecast horizon\n",
    "            target = besttrack_ndarr[idx + forecast_horizon // 3][:4]\n",
    "            \n",
    "            if cnn_input is None or track_input is None or target is None:\n",
    "                print(\"None found in generator output!\")\n",
    "                continue  # or handle it differently as needed\n",
    "            \n",
    "            # print(\"Yielding data:\", cnn_input.shape, track_input.shape, target.shape)\n",
    "            # Yield the individual data sample and target\n",
    "            yield ((cnn_input, track_input), target)\n",
    "\n",
    "# Define output signatures to specify the shapes and types of outputs expected\n",
    "output_signature = (\n",
    "    (\n",
    "        tf.TensorSpec(shape=(13, *gridShape, 60), dtype=tf.float32),  # CNN input shape\n",
    "        tf.TensorSpec(shape=(6,), dtype=tf.float32)  # Best track input shape\n",
    "    ),\n",
    "    tf.TensorSpec(shape=(4,), dtype=tf.float32)  # Output target shape\n",
    ")\n",
    "\n",
    "# Create a TensorFlow dataset from the generator, specifying batch size within the dataset pipeline\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: data_generator(inTensor, besttrack_ndarr, startFrameinA, endFrameinA),\n",
    "    output_signature=output_signature\n",
    ").batch(3)  # Define batch size here\n",
    "\n",
    "# Example usage: Ready for model training\n",
    "# model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 853ms/step - loss: 0.2025\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 793ms/step - loss: 0.0042\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 792ms/step - loss: 0.0017\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 755ms/step - loss: 0.0018\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 780ms/step - loss: 0.0011\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 758ms/step - loss: 0.0012\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 771ms/step - loss: 7.3896e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 753ms/step - loss: 6.6126e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 777ms/step - loss: 5.1188e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 785ms/step - loss: 4.4176e-04\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(x=dataset, steps_per_epoch=10, epochs=4)\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_grib(fname,cname):\n",
    "    global numFrames,numDays,cyc_name\n",
    "    gribName=fname\n",
    "    cyc_name=str.upper(cname)\n",
    "    grbs = pygrib.open('.\\\\Data\\\\'+gribName+'.grib')\n",
    "    grb=grbs[1:]\n",
    "    grb.append(grbs[len(grb)+1])\n",
    "    \n",
    "    numFrames=len(grb)\n",
    "    numDays=numFrames//(numChannels*framesPerDay*numIsoLvls)\n",
    "    #INDEX=Frame*5*12+IsoLvl*12+Channel (tot=12*5*24*numDays)\n",
    "    assert numFrames%(numChannels*framesPerDay*numIsoLvls)==0 #Having integer number of days\n",
    "    assert grb[1].values.shape==gridShape #Check grid shape matches\n",
    "\n",
    "        \n",
    "    for i,v in enumerate(grb):\n",
    "        arr[*parseIndices(i)] = v.values.astype(\"float32\")\n",
    "\n",
    "    del grb\n",
    "    del grbs\n",
    "    \n",
    "    \n",
    "    normalized_arr = normalize_channels(arr)\n",
    "    transposed_arr = np.transpose(normalized_arr, (0, 3, 4, 1, 2))\n",
    "\n",
    "    # Now, we need to merge the last two dimensions (numIsoLvls and numChannels)\n",
    "    # Calculate the new dimension\n",
    "    new_last_dim = transposed_arr.shape[3] * transposed_arr.shape[4]\n",
    "\n",
    "    # Reshape to merge the last two dimensions\n",
    "    inTensor = transposed_arr.reshape(transposed_arr.shape[0], transposed_arr.shape[1], transposed_arr.shape[2], new_last_dim)\n",
    "\n",
    "    best_Track=pd.read_csv(\"BestTrack_Trimmed.csv\")\n",
    "    starttime=pd.to_datetime(gribName[:8],format='%Y%m%d')\n",
    "    endtime=starttime+pd.Timedelta(days=numDays)\n",
    "    fBesttrack=best_Track[(best_Track['ISO_TIME']>=starttime)&(best_Track['ISO_TIME']<=endtime)&(best_Track['LAT']>=0.0)&(best_Track['LAT']<=90.0)&(best_Track['LON']>=-170.0)&(best_Track['LON']<=-80.0)&(best_Track['NAME']==cyc_name)]\n",
    "    selected_columns = fBesttrack[['USA_WIND', 'USA_PRES', 'LAT', 'LON','ISO_TIME']]\n",
    "    selected_columns=selected_columns[selected_columns['ISO_TIME'].dt.hour%3==0]\n",
    "\n",
    "    # Normalize the besttrack data\n",
    "    selected_columns['LAT'] = normalize(selected_columns['LAT'], lat_min, lat_max)\n",
    "    selected_columns['LON'] = normalize(selected_columns['LON'], lon_min, lon_max)\n",
    "    selected_columns['USA_WIND'] = normalize(selected_columns['USA_WIND'].astype(float), wind_min, wind_max)\n",
    "    selected_columns['USA_PRES'] = normalize(selected_columns['USA_PRES'].astype(float), pressure_min, pressure_max)\n",
    "    selected_columns['ISO_DATE'] = selected_columns['ISO_TIME'].dt.dayofyear/365\n",
    "    selected_columns['ISO_TIME'] = selected_columns['ISO_TIME'].dt.hour/24\n",
    "\n",
    "    starttimeb=fBesttrack['ISO_TIME'].iloc[0]\n",
    "    endtimeb=fBesttrack['ISO_TIME'].iloc[-1]\n",
    "    assert (endtimeb-starttimeb)/datetime.timedelta(seconds=3*3600) == len(selected_columns)-1 #same frame count\n",
    "    besttrack_ndarr=selected_columns.to_numpy().astype(\"float32\")\n",
    "\n",
    "    startFrameinA=int((starttimeb-starttime)/datetime.timedelta(hours=1))\n",
    "    endFrameinA=int((endtimeb-starttime)/datetime.timedelta(hours=1))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator=lambda: data_generator(inTensor, besttrack_ndarr, startFrameinA, endFrameinA),\n",
    "        output_signature=output_signature\n",
    "    ).batch(3)  # Define batch size here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=dataset, steps_per_epoch=10, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
